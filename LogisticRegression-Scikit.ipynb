{
 "metadata": {
  "name": "",
  "signature": "sha256:c50c2ddb53e821d725b69dcfd9fb458333002bf4ca79d50569cba19d8c51b527"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np \n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "import pylab as pl\n",
      "import csv\n",
      "from sklearn import svm\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "from sklearn import preprocessing\n",
      "\n",
      "dat = pd.read_csv(\"got_A-1.csv\")\n",
      "print dat.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   univ_GPA  hours_study  got_A\n",
        "0      3.52          0.0      0\n",
        "1      2.91          4.1      0\n",
        "2      2.40         10.8      0\n",
        "3      3.47          5.6      0\n",
        "4      3.47          6.1      0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X= dat\n",
      "y= dat.got_A\n",
      "del X[\"got_A\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.head()\n",
      "print y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   univ_GPA  hours_study\n",
        "0      3.52          0.0\n",
        "1      2.91          4.1\n",
        "2      2.40         10.8\n",
        "3      3.47          5.6\n",
        "4      3.47          6.1\n",
        "0    0\n",
        "1    0\n",
        "2    0\n",
        "3    0\n",
        "4    0\n",
        "Name: got_A, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "model = LogisticRegression(C=1)\n",
      "model = model.fit(X,y)\n",
      "model.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.81000000000000005"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[-0.49664659,  0.35261344]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "expected = y\n",
      "predicted = model.predict(X)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.84      0.95      0.89        80\n",
        "          1       0.56      0.25      0.34        20\n",
        "\n",
        "avg / total       0.78      0.81      0.78       100\n",
        "\n",
        "[[76  4]\n",
        " [15  5]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above model is generated considering complete data set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Splitting the data set into test and train f"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.utils import shuffle\n",
      "X, y = shuffle(X,y)\n",
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=0)\n",
      "model = LogisticRegression(C=1)\n",
      "model = model.fit(X_train, y_train)\n",
      "print model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.score(X_train,y_train)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.82499999999999996"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The default metric for logistic regression is mean accuracy:\n",
      "\n",
      "accuracy(y,y\u0302 )=1n\u2211i=1n\ud835\udd40(y\u0302 i=yi)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([[-0.70697476,  0.36673725]])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs = model.predict_proba(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.8321225   0.1678775 ]\n",
        " [ 0.77235171  0.22764829]\n",
        " [ 0.8501165   0.1498835 ]\n",
        " [ 0.91750214  0.08249786]\n",
        " [ 0.44333186  0.55666814]\n",
        " [ 0.87368084  0.12631916]\n",
        " [ 0.76113107  0.23886893]\n",
        " [ 0.80059018  0.19940982]\n",
        " [ 0.89599459  0.10400541]\n",
        " [ 0.93515442  0.06484558]\n",
        " [ 0.97569488  0.02430512]\n",
        " [ 0.77621218  0.22378782]\n",
        " [ 0.85129447  0.14870553]\n",
        " [ 0.6737061   0.3262939 ]\n",
        " [ 0.85970446  0.14029554]\n",
        " [ 0.94993582  0.05006418]\n",
        " [ 0.89976304  0.10023696]\n",
        " [ 0.61998596  0.38001404]\n",
        " [ 0.74795926  0.25204074]\n",
        " [ 0.97269966  0.02730034]]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = model.predict(X_test)\n",
      "expected=y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "#The f1-score gives you the harmonic mean of precision and recall. \n",
      "#The scores corresponding to every class will tell you the accuracy of the classifier in classifying the data points in that particular class compared to all other classes.\n",
      "#The support is the number of samples of the true response that lie in that class.\n",
      "#The precision is the ratio tp / (tp + fp\n",
      "#The recall is the ratio tp / (tp + fn) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.68      0.93      0.79        14\n",
        "          1       0.00      0.00      0.00         6\n",
        "\n",
        "avg / total       0.48      0.65      0.55        20\n",
        "\n",
        "[[13  1]\n",
        " [ 6  0]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.8  0.9  0.9  0.9  0.8  0.8  0.8  0.6  0.9  0.7]\n",
        "0.81\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Logistic Regression model with iris dataset\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a logistic regression model to the data\n",
      "model = LogisticRegression()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(dataset.data,dataset.target,test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      1.00      1.00        50\n",
        "          1       0.98      0.90      0.94        50\n",
        "          2       0.91      0.98      0.94        50\n",
        "\n",
        "avg / total       0.96      0.96      0.96       150\n",
        "\n",
        "[[50  0  0]\n",
        " [ 0 45  5]\n",
        " [ 0  1 49]]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Continuation of above\n",
      "import sklearn.cross_validation \n",
      "print sklearn.cross_validation.cross_val_score(model, X_train, y_train, scoring='accuracy')\n",
      "print sklearn.cross_validation.cross_val_score(model, X_train, y_train, scoring='recall')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.87804878  0.975       0.92307692]\n",
        "[ 0.87804878  0.975       0.92307692]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}